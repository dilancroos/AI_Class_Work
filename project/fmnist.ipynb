{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Fashion-MNIST data (https://github.com/zalandoresearch/fashion-mnist). \n",
    "# Bonus if you download the raw files and build the data loaders yourself. \n",
    "# Build a PyTorch pipeline to learn the classification\n",
    "# You will get a bonus if the this pipeline is well-coded : following PyTorch style, using multiprocessing and GPU (request one on Google Collab)\n",
    "# Present the results of different architectures based on different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "from torch.nn import Module, Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnMLP(Module): # inherit from the base class\n",
    "    def __init__(self): # define the constructor\n",
    "        super(MyOwnMLP, self).__init__() # call the constructor of the base class\n",
    "        self.w1 = Parameter(torch.normal(mean=0., std=0.1, size=(784, 100))) # define the parameters\n",
    "        self.b1 = Parameter(torch.normal(mean=0., std=0.1, size=(1, 100))) \n",
    "        self.w2 = Parameter(torch.normal(mean=0., std=0.1, size=(100, 1)))\n",
    "        self.b2 = Parameter(torch.normal(mean=0., std=0.1, size=(1, 1)))\n",
    "        \n",
    "\n",
    "    def forward(self, x): # define the forward pass\n",
    "        step1  = torch.matmul(x, self.w1) # matrix multiplication\n",
    "        step2 = torch.add(step1, self.b1) # addition\n",
    "        step3 = torch.nn.functional.relu(step2) # ReLU # rectified linear unit\n",
    "        step4 = torch.matmul(step3, self.w2)\n",
    "        out = torch.add(step4, self.b2)\n",
    "        return out\n",
    "    \n",
    "model = MyOwnMLP() # create an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): # inherit from the base class\n",
    "    def __init__(self, data_x, data_y): # define the constructor\n",
    "        self.data_x = data_x # store the data\n",
    "        self.data_y = data_y \n",
    "\n",
    "    def __len__(self): # define the length function\n",
    "        length = len(self.data_x) # get the length of the data\n",
    "        return length # return the length\n",
    "\n",
    "    def __getitem__(self, index): # define the get item function\n",
    "        # Get the x and y at a given position (index) in the data\n",
    "        x = self.data_x[index] \n",
    "        y = self.data_y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# training data\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = path + 'train-labels-idx1-ubyte.gz'\n",
    "    images_path = path + 'train-images-idx3-ubyte.gz'\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels\n",
    "\n",
    "# test data\n",
    "def load_mnist_test(path, kind='test'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = path + 't10k-labels-idx1-ubyte.gz'\n",
    "    images_path = path + 't10k-images-idx3-ubyte.gz'\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels_test = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images_test = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels_test), 784)\n",
    "    return images_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist('./data/FashionMNIST/raw/', kind='train')\n",
    "X_test, y_test = load_mnist_test('./data/FashionMNIST/raw/', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784),y_train: (60000,), X_test: (10000, 784), y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape},y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the array to protect its data and make it writable before converting it to a tensor\n",
    "\n",
    "X_train2 = np.copy(X_train)\n",
    "X_test2 = np.copy(X_test)\n",
    "y_train2 = np.copy(y_train)\n",
    "y_test2 = np.copy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.flags.writeable = True\n",
    "X_test2.flags.writeable = True\n",
    "y_train2.flags.writeable = True\n",
    "y_test2.flags.writeable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1])\n"
     ]
    }
   ],
   "source": [
    "torch_data = torch.from_numpy(X_train2).float()\n",
    "torch_labels = torch.from_numpy(y_train2)\n",
    "out = model(torch_data)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_labels.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in pytorch :  0.2186579704284668\n"
     ]
    }
   ],
   "source": [
    "# Loop and wait for each data point in PyTorch\n",
    "dataset = CustomDataset(data_x=X_train2, data_y=y_train2) # create an instance of the dataset\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=10, num_workers=0) # create an instance of the data loader\n",
    "start = time.time() # start the timer\n",
    "for point in dataloader: # loop over the data\n",
    "    pass\n",
    "print('Done in pytorch : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'gpu' if torch.cuda.is_available() else 'cpu' # check if cuda is available\n",
    "torch_xs = torch_data.to(device) # move the data to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.04637336730957\n",
      "10 7.28519344329834\n",
      "20 7.28519344329834\n",
      "30 7.28519344329834\n",
      "40 7.28519344329834\n",
      "50 7.28519344329834\n",
      "60 7.28519344329834\n",
      "70 7.28519344329834\n",
      "80 7.28519344329834\n",
      "90 7.28519344329834\n",
      "100 7.28519344329834\n",
      "110 7.28519344329834\n",
      "120 7.28519344329834\n",
      "130 7.28519344329834\n",
      "140 7.28519344329834\n",
      "150 7.28519344329834\n",
      "160 7.28519344329834\n",
      "170 7.28519344329834\n",
      "180 7.28519344329834\n",
      "190 7.28519344329834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 200 # the number of epochs\n",
    "\n",
    "model = MyOwnMLP() # create an instance of the model\n",
    "model = model.to(device) # move the model to the device\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01) # the optimizer with the parameters to optimize and the learning rate\n",
    "\n",
    "dataset = CustomDataset(data_x=torch_data, data_y=torch_labels) # create an instance of the dataset\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=10, num_workers=0) # create an instance of the data loader\n",
    "\n",
    "for epoch in range(n_epochs): # loop over the epochs\n",
    "    for batch_x, batch_y in dataloader: # loop over the data\n",
    "        # Don't forget to send to device, the rest is similar to what we had above\n",
    "        batch_x = batch_x.to(device) \n",
    "        batch_y = batch_y.to(device) \n",
    "        opt.zero_grad() \n",
    "        loss = torch.mean((model(batch_x) - batch_y) ** 2) # compute the loss\n",
    "        loss.backward() # compute the gradients\n",
    "        opt.step() # update the parameters\n",
    "    if epoch % 10 == 0: # print the loss every 10 iterations\n",
    "        print(epoch, loss.item())\n",
    "\n",
    "# Let's plot our trained model\n",
    "torch_lsp = torch.from_numpy(X_train2).float()[:, None] \n",
    "# torch_lsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To easily use the trained model we need to send it back to cpu at the end\n",
    "model = model.to('cpu') # move the model to the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0: 'T-shirt/top',\n",
    "          1: 'Trouser',\n",
    "          2: 'Pullover',\n",
    "          3: 'Dress',\n",
    "          4: 'Coat',\n",
    "          5: 'Sandal',\n",
    "          6: 'Shirt',\n",
    "          7: 'Sneaker',\n",
    "          8: 'Bag',\n",
    "          9: 'Ankle Boot'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
